\chapter{Implementacja Systemu}
\label{ch:implementacja_systemu}

Realizacja systemu, którego architekturę oraz projekt przedstawiono w poprzednim rozdziale, wymagała doboru nie tylko odpowiednich technologii, 
ale także właściwych standardów wytwarzania oprogramowania. Ninjeszy rozdział opisuje proces implementacji poszczególnych warstw aplikacji, zaczynając 
od interfejsu użytkownika, poprzez logikę biznesową, kończąc na konteneryzacji i telemetrii. 

Aby umożliwić bezpieczne eksperymentowanie i tworzenie nowych funkcjonalności, wykorzystano system kontroli wersji Git, pozwalający na zachowanie 
historii zmian. Cały kod źródłowy aplikacji został umieszczony w repozytorium serwisu GitHub. W repozytorium zastosowano strukturę monorepo, co oznacza 
że kod aplikacji klienckiej i serwera znajduje się w tym samym repozytorium, ale w oddzielnych folderach. Taka organizacja kodu zapewnia centralizację projektu 
i w przypadku jednej osoby pracującej nad kodem, znacznie przyśpiesza proces implementacji.

Implementacja systemu została przeprowadzona w środowisku programistycznym Visual Studio Code. Narzędzie to wybrano ze względu na jego 
szerokie wsparcie dla wykorzystywanych technologii oraz ogromną ilość rozszerzeń usprawniających pracę nad kodem. 
Aby zachować spójność i jakość kodu, skonfigurowano w środowisku automatyczne formatowanie kodu.
Kluczowym aspektem podczas tworzenia oprogramowania jest zapewnie czytelności i łatwości utrzymania aplikacji, 
co zostało zrealizowane poprzez trzymanie się zasad czystego kodu \cite{cleancode}.

\section{Warstwa Prezentacji}
Zgodnie z założeniami projektowymi warstwa prezentacji została zaimplementowana jako aplikacja 
typu SPA przy użyciu biblioteki React i języka TypeScript. Na wczesnym etapie implementacji, ważne 
było sprawne przełożenie projektu interfejsu użytkownika w figmie na czytelną i skalowalną strukturę 
kodu źródłowego (Rys \ref{fig:frontend_structure}). Aplikacja kliencka została podzielona na dwa główne 
katalogi:
\begin{itemize}
    \item \texttt{src/components} -- Katalog zawierający wyłącznie interfejs użytkownika i logikę jego obsługi.
    Wewnątrz jego znajdują się podkatalogi (np. Auth lub FlashCardSet) zawierające komponenty React, które 
    stanowią bezpośrednie odzwierciedlenie projektu w Figmie. Komponenty te odpowiadają za rednerowanie interfejsu 
    i obsługę interakcji z użytkownikiem.
    \item \texttt{src/features} -- Zawiera logikę biznesową aplikacji. W nim zawierają się definicję wycinków 
    (ang. slices) biblioteki Redux Toolkit oraz serwisy odpowiadające za komunikację z API serwera.
\end{itemize} 
Uzupełnieniem tej struktury jest folder \texttt{src/app} zawierający globalną konfigurację sklepu (ang. store) 
oraz niestandardowe haki (ang. hooks). Taka organizacja kodu pozwoliła na zachowanie czytelności projektu i 
ułatwiła jego skalowanie. 

\begin{figure}[h]
    \centering
    \begin{minipage}{0.25\textwidth} 
        \dirtree{%
        .1 /src.
        .2 app.
        .2 components.
        .3 Auth.
        .3 Common.
        .3 FlashcardSet.
        .3 Layouts.
        .3 Materials.
        .3 modals.
        .3 Navbar.
        .3 NewSet.
        .3 PublicPage.
        .3 Sidebar.
        .3 TipTap.
        .2 features.
        .3 auth.
        .3 flashcardSets.
        .3 materials.
        .3 publicPage.
        .3 shares.
        .2 App.tsx.
        .2 main.tsx.
        }
    \end{minipage}
    \caption{Wysokopoziomowa struktura katalogów warstwy prezentacji}
    \label{fig:frontend_structure}
\end{figure}

\subsection{Hybrydowe zarządzanie stanem aplikacji}

Zarządzanie stanem w nowoczesnych aplikacjach typu SPA jest kluczowym elementem decydującym o skalowalności, 
wydajności i łatwości utrzymania systemu. Zgodnie z projektem systemu zaimplementowano hybrydowe zarządzanie stanem. 
Sposób zarządzania stanem zależy od cyklu życia danych oraz liczby interakcji użytkownika z nimi.

Globalny stan jest obsługiwany za pomocą biblioteki Redux Toolkit. Pełni on funkcję głównego magazynu dla danych 
wymagających precyzyjnej kontroli i natychmiastowej dostępności we wszystkich komponentach aplikacji. Globalny stan 
zarządza dwoma typami danych:
\begin{itemize}
    \item \textbf{Dane sesji} -- Slices takie jak \texttt{authSlice} czy \texttt{materialsSlice} przechowują 
    informacje potrzebne do poprawnego działania interfejsu (np. informacja o zalogowaniu użytkownika lub 
    aktualnie otwartym folderze). Interakcje użytkownika z systemem (np. proces logowania czy dodanie folderu), skutkują 
    natychmiastową aktualizacją stanu, będącą odpowiedzią zapytania wysłanego do serwera API.
    \item \textbf{Dane edytowalne} -- Szczegóły zestawu fiszek pobierane z API są zapisywane w \texttt{flashcardSetSlice} 
    i traktowane przez aplikację jako kopia robocza danych. Dzięki temu wszystkie modyfikacje stanu 
    (treści fiszek lub metadanych zestawu) odbywają się synchronicznie w aplikacji klienta, ograniczając liczbę nadmiarowych 
    zapytań do serwera. Takie podejście zapewnia minimalizację opóźnień sieciowych, a synchronizacja zmian z bazą 
    danych (serwerem) odbywa się dopiero w przypadku zatwierdzenia zmian przez użytkownika.
\end{itemize}

Podczas wylogowywania użytkownika zostają usuwane ciasteczka, dzięki czemu użytkownik nie ma dostępu do większości zapytań 
API. Jako że informacja o zalogowaniu użytkownika jest przechowywana w stanie globalnym, aplikacja kliencka nadal 
wyświetlałaby użytkownikowi widoki, do których nie miałby dostępu, co prowadziłoby do błędów.
Aby zapewnić prawidłowe wylogowanie użytkownika, stworzono Root Reducer, który 
w momencie wylogowywania (\texttt{logoutUser}), czyści globalny stan aplikacji do wartości początkowych, co skutecznie 
odbiera użytkownikowi uprawnienia do wejścia w np. jego materiały. 

Listing \ref{lst:logout_user} pokazuje konfigurację store Reduxa, poprzez zaimplementowanie rootReducera.
RootReducer pozwala na przechwycenie dowolnej akcji przed jej dotarciem do standardowych reduktorów. 
W tym wypadku zostało to wykorzystane do przechwycenia akcji wylogowującej użytkownika (\texttt{logoutUser}),
dzięki czemu cały stan aplikacji jest resetowany do wartości początkowych. Wyjątkiem jest status modułu 
uwierzytelniania, który jest ustawiany na wartość \texttt{"failed"}, aby zapobiec zablokowaniu interfejsu 
w stanie oczekiwania na ustalenie stanu sesji. Główny komponent aplikacji (Listing \ref{lst:app_tsx}) 
wstrzymuje renderowanie widoków do momentu, aż status sesji zmieni się z domyślnego \texttt{"idle"}, 
co w przypadku pełnego resetu stanu skutkowałoby wyświetleniem pustego ekranu, a nie ekranu logowania.

\begin{lstlisting}[language=Python,
	caption={Konfiguracja Redux z mechanizmem resetowania stanu},
	label={lst:logout_user}]
    const appReducer = combineReducers({
        materials: materialsReducer,
        auth: authReducer,
        flashcardSet: flashcardSetReducer,
        shares: sharesReducer,
    });

    const rootReducer = (
        state: ReturnType<typeof appReducer> | undefined,
        action: UnknownAction,
    ) => {
        // Wykrycie akcji zakonczenia wylogowania
        if (action.type === logoutUser.fulfilled.type) {
            // Pobranie poczatkowego stanu 
            const initialState = appReducer(undefined, action);
            return {
                ...initialState,
                // Nadpisanie statusu auth na failed
                auth: {
                    ...initialState.auth,
                    status: "failed",
                },
            };
        }
        return appReducer(state, action);
    };

    export const store = configureStore({
        reducer: rootReducer,
    });
\end{lstlisting} 

\begin{lstlisting}[language=Python,
caption={Mechanizm blokady renderowania aplikacji do czasu ustalenia statusu sesji},
label={lst:app_tsx}]
function App() {
    const authStatus = useAppSelector((state) => state.auth.status);

    if (authStatus == "loading" || authStatus == "idle") {
        return <div className="App"></div>;
    }
    ...
}
\end{lstlisting} 

Drugą podstawą hybrydowego modelu jest obsługa danych tylko do odczytu, które są niezależne od kontekstu sesji. 
Dane te nie wymagające dodatkowej logiki biznesowej po stronie klienta, zarządzane są poprzez bibliotekę 
TanStack Query (React Query). Automatyzuje ona proces pobierania, buforowania i inwalidacji danych. 

React Query został wykorzystany w module publicznym aplikacji, gdzie wyświetlane są różne 
rankingi zestawów (np. "Najpopularniejsze", "Najczęściej wyświetlane"). Kluczowym elementem optymalizacji
jest konfiguracja parametru \texttt{staleTime}. Dzięki niemu zminimalizowano liczbę nadmiarowych zapytań sieciowych 
podczas nawigacji między widokami. Mechanizm ten w pierwszej kolejności pobiera dane z pamięci podręcznej, 
a dopiero po upłynięciu czasu zdefiniowanego w \texttt{staleTime}, wysyłane zostaje zapytanie do API, w 
celu uaktualnienia zbuforowanych danych.

\subsection{Komunikacja z serwerem i uwierzytelnianie}
Asynchroniczna komunikacja klienta z serwerem stanowi podstawę działania aplikacji typu SPA. Do komunikacji 
z serwerem API użyto bilbioteki Axios. Została ona wybrana ponad wbudowany w JavaScript fetch ze względu na 
możliwości konfiguracji, wbudowany obsługę formatu JSON oraz zaawansowany mechanizm przechwytywania żądań i odpowiedzi
(ang. interceptor).

W celu zapewnienia spójności i zminimalizowniu redundancji kodu skonfigurowano globalne ustawienia bilbioteki Axios. 
Zgodnie z wymaganiami zdefiniowanymi w rozdziale \ref{ch:projekt_systemu}, komunikacja między klientem 
a serwerem opiera się na ciasteczkach sesyjnych. Dzięki ustawieniu parametru \texttt{withCredentials} biblioteki Axios
na \texttt{true} przeglądarka automatycznie dołącza ciasteczko z tokenem uwierzytelniającym do każdego zapytania wysyłanego do API.

Kluczowym elementem warstwy komunikacji jest zapewnienie bezpieczeństwa użytkowników. Aplikacja aby zabezpieczać przed 
atakami typu CSRF po udanym logowaniu lub odświeżeniu sesji, otrzymuje token CSRF w odpowiedzi od serwera. Token ten jest 
przechowywany w globalnym stanie aplikacji (Redux) i automatycznie dołączany do nagłówka \texttt{X-CSRF-TOKEN} każdego żądania, co 
pozwala serwerowi na weryfikację poprawności źródła żądania. 

Największym wyzwaniem implementacyjnym w warstwie uwierzytelniania było odświeżanie sesji użytkownika. Ze względu na krótki czas życia 
tokenu dostępu (\texttt{Access Token}), aplikacja musi go automatycznie odświeżać bez dodatkowej ingerencji użytkownika. W tym celu zaimplementowano 
interceptor odpowiedzi (ang. Response Interceptor).

Interceptor działa jako pośrednik w komunikacji między klientem a serwerem. Przechwytuje on błędy HTTP o kodzie \texttt{401} (\texttt{Unauthorized}) 
w celu odnowienia tokenu dostępu i ponownego wysłania zapytania. Algorytm interceptora przedstawiony na listingu \ref{lst:interceptor} 
działa następująco:
\begin{enumerate}
    \item Interceptor monitoruje wszystkie odpowiedzi otrzymane od serwera. W przypadku wystąpienia błędu \texttt{401} wstrzymuje 
    wyrzucenie błędu do wyższych warstw aplikacji.
    \item W celu zapobiegnięcia nieskończonym pętlom zapytań aplikacja sprawdza, czy błąd nie wystąpił w zapytaniu do endpointów 
    obsługujących autoryzację (\texttt{/login}, \texttt{/register}, \texttt{/logout} czy \texttt{/refresh}). Błędy w tych zapytaniach 
    zwracane są natychmiastowo, bez próby ponownego odświeżenia sesji.
    \item Jeżeli warunki są spełnione, aplikacja wysyła zapytanie do endpointu \texttt{/refresh}.
    \item W przypadku sukcesu (aktywnego tokenu odświeżania), serwer zwraca w odpowiedzi nowy token CSRF oraz odświeżony 
    token dostępu w ciasteczku HTTP, a oryginalne zapytanie (zakończone kodem 401) jest ponawiane.
    \item Jeżeli odświeżenie tokenu dostępu zakończy się niepowodzeniem (np. token odświeżenia już wygasł), interceptor automatycznie 
    wylogowuje użytkownika, czyszcząc stan aplikacji.
\end{enumerate}

\begin{lstlisting}[language=Python,
caption={Mechanizm interceptora do odświeżania sesji użytkownika},
label={lst:interceptor}]
export const setupAxiosInterceptor = (store: AppStore) => {
    axios.interceptors.response.use(
        (response) => response,
        async (error) => {
            const originalRequest = error.config;
            ...
            if (
                error.response.status === 401 &&
                !originalRequest._retry &&
                ...
            ) {
                originalRequest._retry = true;
                try {
                    const { csrf_token } = await refreshTokenApi();

                    store.dispatch(setCsrfToken(csrf_token));
                    originalRequest.headers["X-CSRF-TOKEN"] = csrf_token;
                    return axios(originalRequest);
                } catch (refreshError) {
                    store.dispatch(logoutUser());
                    return Promise.reject(refreshError);
                }
            }
            return Promise.reject(error);
        },
    );
};
\end{lstlisting} 

\subsection{Edytor fiszek}
Centralnym elementem modułu tworzenia i edycji zestawów fiszek jest edytor tekstu typu WYSIWYG 
(What You See Is What You Get). Zgodnie z projektem systemu, edytor musi umożliwiać nie tylko 
formatowanie tekstu fiszki, ale także wstawianie multimediów i tworzenie złożonych układów.
Omawiany wcześniej framework TipTap udostępnia edytor headless, co oznacza, że udostępnia on 
jedynie silnik edycji tekstu a cały interfejs użytkownika musi zostać zaimplementowany przez 
programistę. Takie podejście pozwoliło na zaimplementowanie intuicyjnego i łatwego w obsłudze 
edytora tekstu, zgodnego z projektem w Figmie.

Implementacja edytora opiera się na inicjalizacji instancji silnika TipTap za pomocą wbudowanego haka 
\texttt{useEditor}. Dodatkowo edytor został skonfigurowany przekazując mu tablicę rozszerzeń, 
które determinują funkcjonalności przetwarzania tekstu. Oprócz standardowego zestawu rozszerzeń 
\texttt{StarterKit} wykorzystano także moduły \texttt{Underline}, \texttt{Highlight} i \texttt{TextAlign}, 
które znacznie zwiększają możliwości edycji tekstu przez użytkownika.

Obsługa edytora przez użytkownika odbywa się za pomocą komponentu \texttt{MenuBar.tsx}. Jako że TipTap 
nie udostępnia interfejsu użytkownika, MenuBar obsługuję interakcję użytkownika z silnikiem TipTap. 
Każdy przycisk znajdujący się na pasku narzędzi wywołuje sekwencję metod na obiekcie edytora za pomocą 
łańcucha poleceń: \texttt{editor.chain().focus().toggleBold().run()}. Dzięki użyciu metody \texttt{focus}, 
edytor utrzymuje pole tekstowe jako aktywne, nawet po kliknięciu przycisku formatowania (np. pogrubiania), 
co znacznie poprawia pracę nad tekstem.

Największym wyzwaniem implementacyjnym w tym module było stworzenie funkcjonalności dodawania obrazów 
i tworzenia ich niestandardowych układów. TipTap udostępnia rozszerzenie \texttt{Image}, które pozwala na 
wstawienie obrazu do edytora tekstowego. Pozwala ono jednak tylko na wyświetlanie obrazków na podstawie 
podanego adresu URL, nie zapewniając interfejsu do wyboru plików ani procesu przesłania plików na serwer.
W celu rozwiązania tego problemu stworzono niestandardowe rozszerzenie \texttt{CustomImage}, wykorzystujące 
mechanizm React Node View. Mechanizm ten pozwala na wstrzyknięcie interaktywnego komponentu React 
(\texttt{InteractiveImage}) w strukturę widoku dokumentu (DOM), zastępując domyślną, statyczną reprezentację 
węzła obrazu.

Komponent \texttt{InteractiveImage} początkowo wyświetla przycisk pozwalający na wstawienie pliku. Po wybraniu 
obrazu przez użytkownika, plik jest asynchronicznie przesyłany na serwer, który zwraca publiczny adres URL zasobu. 
Dopiero po otrzymaniu odpowiedzi od serwera atrybut src jest aktualizowany o adres URL otrzymany od serwera, 
co powoduje natychmiastowe wyświetlenie obrazu w miejscu przycisku.

Aby umożliwić użytkownikom tworzenie fiszek o niestandardowym formacie, stworzono niestandardowe rozszerzenie 
\texttt{ImageGrid}. \texttt{ImageGrid} pozwala na tworzenie rzędu obrazków z możliwością konfiguracji liczby kolumn.
Kod rozszerzenia został przedstawiony na listingu \ref{lst:image_grid}.

\begin{lstlisting}[language=python, 
caption={Fragment autorskiego rozszerzenia ImageGrid}, 
label={lst:image_grid}]
export const ImageGrid = Node.create({
    name: "imageGrid",
    group: "block",
    content: "image+",
    draggable: true,

    ...

    renderHTML({ HTMLAttributes }) {
        return [
            "div",
            mergeAttributes(HTMLAttributes, {
                "data-type": "image-grid",
                "data-cols": HTMLAttributes.cols,
                style: `--cols: ${HTMLAttributes.cols}`,
            }),
            0,
        ];
    },
});
\end{lstlisting}

Rozszerzenie zezwala tylko na zawartość \texttt{image+} co wymusza, aby wewnątrz siatki znajdowały się tylko i wyłącznie obrazy.
Kluczowym elementem implementacji jest metoda \texttt{renderHTML}, która dynamicznie tworzy div ze wstrzykniętą zmienną CSS \texttt{--cols}.
Dzięki temu zaimplementowany CSS: \texttt{grid-template-columns: repeat(var(--cols), 1fr)} automatycznie dostosowuje układ siatki 
bez konieczności wykonywania dodatkowych obliczeń po stronie JavaScriptu.

\section{Warstwa Logiki}
Backend zgodnie z projektem systemu, został zaimplementowany w języku Python, przy wykorzystaniu 
frameworku FastAPI. W przeciwieństwie do projektu systemu, gdzie opisywano podział logiczny, ten rozdział 
będzie opisywał organizację kodu, konfigurację serwera i mechanizmy scalające poszczególne komponenty systemu.

Kod źródłowy serwera jest zorganizowany w pakiety, odzwierciedlające podział na warstwy przyjęty podczas projektowania:
\begin{itemize}
    \item {\texttt{api/routes}} -- Zawiera definicję punktów końcowych, z których korzysta aplikacja kliencka.
    \item {\texttt{services}} -- Implementuje logikę biznesową aplikacji. Serwisy przetwarzają dane uzyskane od repozytoriów 
    i przekazują je do tras.
    \item {\texttt{repositories}} -- Warstwa dostępu do danych. Cały kod znajdujący się w tym pakiecie wykonuje bezpośrednie 
    zawołania do bazy danych, Elasticsearch lub MinIO w celu pobrania danych.
    \item {\texttt{api/schemas}} -- Przechowuje modele Pydantic (DTO) dla poszczególnych modułów.
    \item {\texttt{core}} -- Zawiera podstawowe konfiguracje systemu i często wykorzystywane funkcje pomocnicze.
    \item {\texttt{db}} -- Odpowiada za definicję modeli ORM oraz konfigurację połączenia z relacyjną bazą danych.
    \item {\texttt{external}} -- Zawiera pliki odpowiedzialne za inicjalizację i obsługę zewnętrznych systemów 
    (MinIO, ElasticSearch, Gemini).
\end{itemize}
Taka separacja pozwala na łatwe testowanie i utrzymanie kodu, ponieważ zmiany 
w logice biznesowej aplikacji, nie wymagają zmian w pakietach routes i repositories.
Każdy moduł systemu, zobrazowany na diagramie modułów funkcjonalności systemu 
(Rys \ref{rys:use_case_diagram}), posiada oddzielny router, serwis i repozytorium, 
co znacznie ułatwia poruszanie się po bazie kodu. 

Aplikacja do przechowywania wrażliwych danych konfiguracyjnych wykorzystuje bibliotekę pydantic-settings. 
Pozwala ona na walidowanie i wczytywanie wrażliwych danych (klucze API, sól, itp. ) z pliku .env do
klasy Settings. Dzięki temu aplikacja nie uruchomi się, jeżeli zabraknie któregoś z parametrów konfiguracyjnych 
w pliku .env.

Punktem wejściowym całego serwera jest plik main.py, w którym tworzony jest obiekt FastAPI. Podczas tworzenia instancji 
FastAPI, definiowany jest także cykl życia aplikacji. Pozwala on na zainicjalizowanie serwisów przed rozpoczęciem 
przyjmowania żądań od klienta i uruchomienie kodu czyszczącego po zakończeniu działania serwera. Szczególną rolę w tym procesie 
odgrywa zarządzanie połączeniami do poszczególnych źródeł danych. Tak jak wspomniano w rozdziale Projekt Systemu, zainicjalizowane 
zasoby są udostępniane komponentom systemu za pomocą mechanizmu wstrzykiwania zależności (Dependency Injection). W zależności od 
zasobu, przyjęto odmienne strategie zarządzania jego cyklem życia:
\begin{itemize}
    \item {\textbf{Relacyjna baza danych}} -- Do zarządzania połączeniem do relacyjnej bazy danych użyto mechanizmu sesji na żądanie 
    (session per request). Oznacza to, że każde zapytanie do serwera otrzymuje swoje własne połączenie do bazy danych, które wygasa po zwróceniu 
    wyniku do klienta.
    \item {\textbf{Wyszukiwarka pełnotekstowa}} -- Wyszukiwarki pełnotekstowe takie jak Elasticsearch posiadają wewnętrznego klienta 
    , który zarządza jego pulą połączeń HTTP. Do zarządzania jego cyklem życia stosuje się wzorzec Singleton. Oznacza to, że podczas inicjalizacji 
    aplikacji tworzona jest jedna wspólna instancja klienta ElasticSearch, która jest współdzielona przez wszystkie wątki i żądania. Dzięki temu aplikacja unika 
    kosztownego narzutu tworzenia nowego klienta dla każdego żądania.
\end{itemize}
Poniższy listing pokazuje implementację obu wyżej omówionych strategi. Funkcja \texttt{get\_db} wykorzystuje block try...finally
do bezpiecznego zamknięcia połączenia niezależnie od wyniku operacji. Z kolej funkcja \texttt{get\_es\_client} zwraca referencję do 
wcześniej zainicjalizowanego globalnego obiektu.

\begin{lstlisting}[language=Python,
	caption={Startegie zarządzania cyklem życia obiektu},
	label={lst:cykl_zycia}]
    # Session per request
    def get_db():
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()
    
    # Singleton
    def get_es_client():
        if es_client is None:
            raise RuntimeError(
                "Elasticsearch client is not initialized"
            )
        return es_client
\end{lstlisting} 


\subsection{Moduł Uwierzytelniania i zarządzania kontem}
Bezpieczeństwo aplikacji jest podstawą każdego systemu. Wszystkie mechanizmy powiązane z uwierzytelnianiem i zarządzaniem kontem 
znajdują się w serwisie \texttt{AuthService} i pakiecie \texttt{core.security}. W przeciwieństwie do prostych rozwiązań opierających 
się na przesyłaniu tokenów JWT w nagłówkach HTTP, zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów,
zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów. Proces logowania i utrzymywania sesji 
opiera się na dwóch tokenach:
\begin{itemize}
    \item \textbf{Access token} -- Krótkoterminowy token dostępu (ważny przez 5 minut) pozwalający na autoryzację użytkownika.
    \item \textbf{Refresh token} -- Długoterminowy token odświeżania (ważny przez 30 minut) służący do odnawiania sesji użytkownika, bez 
    konieczności ponownego logowania.
\end{itemize}
Oba tokeny nie są zwracane w ciele odpowiedzi (co tworzy podatność na ataki XSS), lecz ustawiane są jako ciasteczka z flagą \texttt{HttpOnly}. 
Takie rozwiązanie ma swoje wady i zalety, ponieważ uniemożliwia ono kradzież tokenów przy pomocy ataku XSS, 
lecz tworzy nowe zagrożenia takie jak np. atak Man-in-the-Middle (MitM) czy Cross-Site Request Forgery (CSRF). W celu zapobiegania tym 
atakom ciasteczko tworzone jest z dwiema dodatkowymi flagami:
\begin{itemize}
    \item \textbf{Secure} -- Przeglądarka dołącza ciasteczko z tokenem tylko wtedy, gdy strona korzysta z protokołu HTTPS, dzięki czemu 
    ciasteczko zawsze będzie zaszyfrowane.
    \item \textbf{SameSite=lax} -- Ogranicza wysyłanie ciasteczka między stronami. W trybie lax przeglądarka blokuje przesyłanie ciasteczka 
    do żądań zainicjowanych przez zewnętrzne serwisy, ale zezwala na jego przesłanie podczas nawigacji najwyższego poziomu (np. kliknięcie w link nawigujący do
    mojej aplikacji).
\end{itemize}
Ustawienie SameSite na \texttt{lax} lub \texttt{strict} nie broni całkowicie przed atakami CSRF. 
W przypadku ustawienia SameSite na \texttt{lax} atakujący może wymusić wysłanie żądania z ciasteczkiem, 
inicjując nawigację najwyższego poziomu za pomocą prostego żądania GET. Ustawienie SameSite na \texttt{strict} 
komplikuje atak, ale nadal można go przeprowadzić poprzez przekierowania po stronie klienta lub podatności na subdomenach.
W celu większego zabezpieczenia przed tym atakiem zaimplementowano wzorzec Signed Double Submit Cookie. Mechanizm ten 
polega na podpisaniu tokenu zapisanego w ciasteczku CSRF przy użyciu sekretnego klucza serwera. Podczas weryfikacji żądania 
serwer najpierw sprawdza poprawność podpisu tokena w ciasteczku, a następnie porównuje jego zawartość z tokenem przesłanym w 
nagłówku HTTP.

W serwerze zostały zaimplementowane dwa sposoby uwierzytelniania użytkownika oparte o mechanizm wstrzykiwania zależności:
\begin{itemize}
    \item \textbf{get\_current\_user} -- Stosowane do uwierzytelnienia użytkownika i uzyskania jego obiektu z bazy danych. 
    Używane w większości tras wymagających autoryzacji (np. tworzenie folderu, edycja materiałów). Weryfikuje on obecność 
    i poprawność access tokenu w ciasteczku przesłanym w żądaniu. W przypadku jego braku lub niezgodności, żądanie jest 
    przerywane błędem 401.
    \item \textbf{get\_optional\_current\_user} -- Stosowane w endpoincie do pobrania zestawu fiszek (\texttt{GET /sets/{id}}) 
    w celu sprawdzenia czy użytkownik jest zalogowany. W przypadku zalogowanego użytkownika system zwróci dodatkowe informacje, 
    takie jak np. głos użytkownika (upvote/downvote) i zapisze zestaw fiszek w ostatnio odwiedzanych zestawach. Niezalogowany użytkownik 
    otrzyma dostęp do zestawu fiszek, bez potrzeby logowania.
\end{itemize}

Największym wyzwaniem w implementacji tego rozwiązania było połączenie asynchronicznej biblioteki walidującej CSRF (fastapi\_csrf\_protect) 
z synchronicznymi endpointami. Zdefiniowanie punktów końcowych jako asynchroniczne znacznie spowolniłoby działanie aplikacji, ponieważ serwer 
używa synchronicznego sterownika bazy danych i ElasticSearch'a, co doprowadziłoby do zablokowania  głównej pętli zdarzeń (Event Loop). Problem 
ten rozwiązano wykorzystując wzorzec wstrzykiwania zależności. Walidację tokenu CSRF wydzielono do asynchronicznej funkcji, która uruchamiana 
jest asynchroniczne przed właściwą logiką endpointu. FastAPI jest w stanie optymalnie zarządzać kontekstem wykonania: walidacja tokena uruchamia 
się na pętli zdarzeń, a logika endpointu jest delegowana do osobnej puli wątków.

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    # Funkcja pomocnicza
    async def validate_csrf(
        request: Request, 
        csrf_protect: CsrfProtect = Depends()
    ):
        await csrf_protect.validate_csrf(request)

    # Endpoint w ktorym walidowany jest CSRF
    @router.post(
        "/materials/{material_id}/comments", 
        status_code=status.HTTP_201_CREATED, 
        response_model=CommentOut
    )
    def new_comment(
        material_id: int, 
        comment_data: CommentCreate, 
        db: Session = Depends(get_db), 
        current_user: User = Depends(get_current_user),
        comment_service: CommentService = Depends(CommentService),
        _ = Depends(validate_csrf)
    ):
        ...
\end{lstlisting} 
 
\subsection{Zarządzanie materiałami i zestawami fiszek}
Centralnym elementem aplikacji jest zarządzanie zasobami użytkownika. Na zasoby użytkownika składają się foldery i zestawy fiszek. Ze względu 
na chierachiczną strukturę danych i różne relacje między zasobami logika została podzielona na dwa współpracujące ze sobą serwisy: 
\texttt{MaterialService} i \texttt{FlashcardSetService}.

Zgodnie z przyjętym modelem bazy danych każdy materiał (folder/zestaw fiszek) jest reprezentowany przez encję \texttt{Materials}. Serwis 
\texttt{MaterialService} powstał w celu uniknięcia duplikacji kodu i odpowiada za podstawowe operacje wykonywane na materiałach 
(przenoszenie między folderami, zmiana nazwy itp.). Jest on warstwą abstrakcyjną nad operacjami wspólnymi dla wszystkich typów materiałów. 
Kluczowym elementem tego serwisu jest metoda 
\texttt{check\_permission}, która realizuje autoryzację do poszczególnych materiałow. Przed wykonaniem jakiejkolwiek operacji na zasobie, 
system za pomocą tej metody weryfikuje uprawnienia użytkownika w oparciu o:
\begin{enumerate}
    \item Własność zasobu (czy owner\_id jest taki sam jak id użytkownika)
    \item Status publiczny zasobu
    \item Udostępnienia zasobu (encja material\_shares)
\end{enumerate} 
Proces tworzenia folderów jest realizowany bezpośrednio przez \texttt{MaterialService}. Metoda \texttt{create\_folder} przyjmuje obiekt DTO, 
waliduje istnienie rodzica (jeżeli został podany) i tworzy nowy wiersz w tabeli materials z \texttt{item\_type="folder"}.  

Tworzenie zestawu fiszek jest bardziej skomplikowane, ponieważ wymaga zapisu do wielu tabel jednocześnie (\texttt{materials}, 
\texttt{flashcard\_sets} i \texttt{flashcards}). Proces ten składa się z dwóch etapów:
\begin{enumerate}
    \item Repozytorium materiałów jest wywoływane w celu stworzenia nowego materiału o typie \texttt{item\_type="set"}. Dzięki temu 
    nowy zestaw fiszek otrzymuje unikalne id i zostaje osadzony w hierarchicznej strukturze folderów.
    \item Następnie serwis wykorzystuje id nowo stworzonego materiału do zapisania szczegołów materiału (opis, widoczność) i listy fiszek
    w odpowiednich tabelach.
\end{enumerate} 

Proces tworzenia zestawu fiszek nie jest jednak najbardziej skomplikowaną operacją w obu tych serwisach. Aktualizacja zestawu fiszek, która 
jest relacją jeden do wielu (zestaw -- fiszki) często implementowana jest poprzez usunięcie wszystkich starych elementów w bazie danych i 
wstawieniu nowych, przychodzących z żądania. Nie jest to jednak idealne podejście, gdyż w przypadku małej zmiany w dużym zestawie fiszek (np. zmiana jednej fiszki), 
musi zostać wykonane N operacji usunięcia i N operacji wstawienia do bazy danych gdzie N to liczba fiszek w zestawie. Z tego powodu zastosowano 
prosty algorytm polegający na pobraniu wszystkich fiszek z bazy danych i porównaniu ich z danymi przychodzącymi z żądania. Fiszki posiadające ID w 
bazie danych są aktualizowane, nieposiadające ID dodawane, a nieistniejące w bazie danych usuwane. Taki mechanizm minimalizuje liczbę operacji 
wykonywanych na bazie danych i zachowuje spójność kluczy głównych fiszek.

Istotnym aspektem opearcji zapisu do bazy danych jest zapewnienie bezpieczeństwa użytkowników, później wyświetlających zapisane dane. 
Jako że aplikacja pozwala na formatowanie tekstu, treść fiszek jest zapisywana i wyświetlana jako HTML, co rodzi ryzyko ataków XSS. 
Aby temu zapobiec, zaimplementowano mechanizm sanityzacji danych wejściowych oraz wyjściowych przekazywanych użytkownikowi. Proces 
sanityzacji danych tekstowych został zaimplementowany przy pomocy biblioteki nh3, która pozwala na zdefiniowanie tagów i atrybutów, 
które nie zostaną zakodowane. Aby ułatwić zarządzanie sanityzacją danych, cały proces oczyszczania został 
zintegrowany w niestandardową definicję typu danych \texttt{SanitizedStr}, stworzoną za pomocą biblioteki Pydantic. SanitizedStr 
wykorzystuje mechanizm \texttt{AfterValidator} do wywołania procesu sanityzacji danych dla każdego pola modelu Pydantic oznaczonego 
tym typem. Takie podejście zapewnia czystość kodu, poprzez automatyzację i centralizację logiki sanityzacji.

\begin{lstlisting}[language=Python,
	caption={Automatyczna sanityzacja w modelach Pydantic},
	label={lst:sanityzacja}]
    # Definicja nowego typu z automatyczna sanityzacja
    SanitizedStr = Annotated[str, AfterValidator(sanitize_html)]

    # Przykladowy model wykorzystujacy nowy typ
    class FlashcardData(BaseModel):
        model_config = ConfigDict(from_attributes=True)

        id: Optional[int] = None
        front_content: SanitizedStr
        back_content: SanitizedStr
\end{lstlisting} 
Zagrożenia bezpieczeństwa systemu nie ograniczają się wyłącznie do danych tekstowych. Jako że aplikacja pozwala na 
wstawianie plików graficznych (danych binarnych) do treści fiszek, użytkownicy mogą spróbować osadzić złośliwe oprogramowanie 
bezpośrednio w zdjęciu (steganografia) lub naruszyć prywatność innych użytkowników poprzez ekstrakcję metadanych obrazu. W 
celu zapobiegania tym atakom wszystkie przesyłane pliki graficzne podlegają weryfikacji i normalizacji. Każda grafika, zanim 
zostanie zapisana w magazynie obiektowym MinIO, jest przetwarzania przez bibliotekę \texttt{Pillow}. Proces przetwarzania 
składa się z trzech kluczowych etapów:
\begin{itemize}
    \item \textbf{Weryfikacja formatu i nagłówków} -- Serwer działa z ograniczonym zaufaniem do użytkownika, 
    analizując magiczne liczby (ang. magic numbers) przesłanego pliku. W ten sposób sprawdzane jest, czy przesłane dane na 
    pewno stanowią poprawny plik wymaganego typu (JPG, PNG lub GIF).
    \item \textbf{Ograniczenie wielkości} -- Aby ochronić zasoby serwera przed wyczerpaniem pamięci i zapobiec atakom typu 
    pixel flood, wszystkie obrazki przekraczające rozdzielczość FULL HD (1920x1080 pikseli) są automatycznie skalowane w dół 
    z zachowaniem oryginalnych proporcji. 
    \item \textbf{Sanityzacja pliku} -- Najważniejszym etapem procesu przetwarzania z punktu widzenia bezpieczeństwa jest 
    rekonstrukcja pliku. Przy pomocy funkcji \texttt{Image.save()} każdy obraz jest dekodowany do pamięci operacyjnej jako mapa bitowa, a następnie zapisywany do nowego 
    strumienia danych. Pozwala to na zachowanie samej zawartości obrazu, bez metadanych (EXIF) i nadmiarowych danych znajdujących 
    się w oryginalnym obrazie, w których mógłby zostać ukryty złośliwy kod.
\end{itemize}

Istotnym wyzwaniem implementacyjnym była obsługa pobierania szczegółów zestawu fiszek (metoda \texttt{get\_full\_set\_details}).
Ze względu na fakt, że wyświetlanie zestawu fiszek jest operacją najczęściej wykonywaną przez użytkowników, proces ten musiał zostać odpowiednio zoptymalizowany. 
Metoda ta pełni rolę agregatora danych, ponieważ pobiera listę fiszek, komentarze, udostępnienia i agreguje głosy. W pierwszej kolejności serwer 
weryfikuje typ materiału. W przypadku napotkania skrótu (\texttt{item\_type="link"}) system pobiera wyżej wspomniane dane z materiału źródłowego, przy 
jednoczesnym zachowaniu uprawnień użytkownika. Cały proces kończy się logowaniem wyświetlenia zestawu fiszek do indeksu 
\texttt{view\_events} w ElasticSearch, co pozwala na późniejsze generowanie rankingu fiszek na stronie publicznej bez obciążania relacyjnej bazy danych.

System umożliwia także funkcjonalność kopiowania zestawów fiszek. Operacja ta pozwala użytkownikowi stworzyć głęboką kopię dowolnego zestawu fiszek, do którego 
posiada dostęp. Logika biznesowa tego procesu polega na utworzeniu nowego materiału o typie \texttt{item\_type="set"}, a następnie zduplikowaniu wszystkich 
powiązanych fiszek z oryginalnego materiału. Dzięki temu użytkownik jest właścicielem zkopiowanego zestawu, co pozwala użytkownikowi na swobodną edycję i nadawanie 
uprawnień bez modyfikacji oryginalnego materiału.

\subsection{Przeglądanie i wyszukiwanie publicznych materiałów}
Implementacja publicznych funkcjonalności wymagała zintegrowania zewnętrznych systemów i wykroczenia poza ramy standardowej relacyjnej bazy danych. 
W przeciwieństwie do innych modułów (obsługujących prywatne materiały), gdzie ważna była spójność transakcji i zasady ACID, w tym przypadku postawiono 
na szybkość obsługi zapytań i asynchroniczne przetwarzanie tekstu.

Zaimplementowanie wyszukiwarki pełnotekstowej wymagało zbudowania odwróconego indeksu, aby jak najbardziej zoptymalizować wyszukiwanie. Jednym z kluczowych 
wyzwań implementacyjnych, był wybór danych, po których działałaby wyszukiwarka. Opieranie mechanizmu wyszukiwania wyłącznie na nazwie i opisie fiszki, mogłoby 
prowadzić do katastrofalnych skutków, gdyż użytkownicy mogliby pozostawić te pola puste lub stosować nazwy nieoddające merytoryki zestawu (np. "Sprawdzian angielski").
Z drugiej strony, podejście polegające na wyszukiwaniu na podstawie treści wszystkich fiszek znajdujących się w zestawie mogłoby prowadzić do nadmiaru danych. Nadmiar 
danych prowadziłby do szumu informacyjnego, więc serwer zwracałby zestawy fiszek zawierające słowo klucz, ale nietrafione kontekstowo.

W celu zapewnienia kompromisu 
między wydajnością a trafnością wyników zaimplementowano mechanizm automatycznego generowania tagów, opisujących zestaw fiszek. Słowa kluczowe generowane są przy 
pomocy modelu językowego Google Gemini 2.5 Flash, który analizuje całą treść tekstową wszystkich fiszek danego zestawu. Do modelu przekazywana jest jedynie treść 
fiszek bez zachowania tagów HTML i plików graficznych. Wstępne przetworzenie tekstu pozwoliło na zminimalizowanie wykorzystywanej liczby tokenów wejściowych, 
zmniejszenie czasu przetwarzania zapytania przez model i ograniczenia informacji przekazywanych do modelu, które mogłyby rozproszyć model, powodując halucynacje.

Kluczowym elementem było stworzenie jasnego zapytania dla modelu, tak aby ten zwrócił jak najbardziej deterministyczną i najtrafniejszą odpowiedź (prompt engeenering). 
Prompt składa się z trzech sekcji:
\begin{itemize}
    \item \textbf{Definicja roli i zadania} -- Nadaje modelowi odpowiedni kontekst, pozwalający na lepsze dopasowanie odpowiedzi.
    \item \textbf{Ustawienie reguł} -- Ograniczenia nałożone na model odgrywają kluczową rolę w formacie jego odpowiedzi.
    \item \textbf{Przekazanie danych} -- Przekazanie nazwy, opisu i zawartości zestawu fiszek.
\end{itemize}

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    prompt = f"""
    You are an expert educational content analyzer and tagging assistant. 
    Your goal is to generate metadata for flashcards to improve searchability.

    Analyze the provided flashcard set and generate a list of relevant semantic tags.

    Rules:
    - Return the tags as a JSON object with a single key named: "tags" which would contain a list of tags (strings).
    - The "tags" list must contain between 5 and 15 strings.
    - Tags should be 1-2 words maximum.
    - Tags HAVE to be in lowercase.
    
    Input Data:
    <flashcard_set>
        <name>{name}</name>
        <description>{description}</description>
        <content>
        {flashcards_content}
        </content>
    </flashcard_set>
    """
\end{lstlisting} 

Google Gemini API pozwala także na konfigurację żądania i zachowania modelu. Zamiast polegać wyłącznie na tekstowych zasadach 
przekazanych w prompcie, zdefiniowano schemat danych wyjściowych przy pomocy modelu biblioteki Pydantic. 
Przekazanie tego schematu do konfiguracji modelu wymusza na nim zwrócenie odpowiedzi w odpowiednim, poprawnym formacie JSON. Skonfigurowano 
także filtry bezpieczeństwa o wysokim progu blokowania (\texttt{BLOCK\_ONLY\_HIGH}), aby zapobiec błędnej klasyfikacji zestawów 
fiszek o tematyce edukacyjnej podobnej do filtrów (np. z zakresu historii wojen czy anatomii człowieka). Obniżono 
temperaturę modelu do 0.2 co ogranicza losowość i czyni jego odpowiedzi bardziej konkretnymi oraz deterministycznymi. Jako dodatkowe 
zabezpieczenie, ograniczono zużycie modelu do 500 tokenów, aby nie zużył on dużej ilości tokenów w przypadku błędnego zinterpretowania 
promptu.

Integracja z zewnętrznymi modelami LLM wiąże się z nieprzewidywalnym czasem odpowiedzi, zależnym od 
rodzaju modelu, informacji mu przekazywanych i długości jego odpowiedzi. Synchroniczne generowanie tagów drastycznie 
zmniejszałoby responsywność aplikacji, blokując główny wątek przetwarzający żądanie HTTP. Aby temu zapobiec, proces 
generowania tagów jest wykonywany przy pomocy zadań w tle (background task). BackgroundTasks jest wbudowanym mechanizmem 
FastAPI pozwalającym na wykonanie metody po zwróceniu odpowiedzi HTTP do użytkownika. Proces generowania tagów jest inicjowany 
przy każdym utworzeniu lub edycji zestawu fiszek. Serwer po otrzymaniu żądania zapisuje zmiany w relacyjnej bazie danych, a następnie 
tuż przed zwróceniem odpowiedzi dodaje zadanie do kolejki w celu wygenerowania i zaindeksowania nowych tagów.

Do implementacji wyszukiwania wykorzystano zapytanie ElasticSearch typu \texttt{multi\_match}, który pozwala na 
przeszukiwanie wielu pól jednocześnie. W podstawowej konfiguracji multi\_match zwraca zestaw o polu posiadającym największy wynik, 
ignorując pozostałe. Aby w pełni wykorzystać zgromadzone dane, rozszerzono konfigurację multi\_match o dwa dodatkowe mechanizmy 
rankingowania:
\begin{itemize}
    \item \textbf{System wag} -- Zastosowany został system wag dla wszystkich pól wyszukiwania. Nazwa zestawu posiada najwyższą wagę (x3),
    wygenerowane tagi średnią (x2), a opis zestawu fiszek najmniejszą (x1).
    \item \textbf{Tie\_breaker} -- Tie breaker pozwala na zsumowanie wyników wyszukiwania ze wszystkich pól, co oznacza, że zestaw fiszek pasujący 
    w nazwie i opisie, nie będzie miał tyle samo punktów co zestaw pasujący tylko w nazwie. Został on ustawiony na wartość 0.3 co powoduje, że do 
    wyniku z najbardziej dopasowanego pola dodawane są wyniki z innych pól pomnożone o wartość tie\_breaker'a.
\end{itemize}
Dodatkowo ustawiony parametr \texttt{fuzziness="AUTO"}, chroni wyszukiwarkę przed literówkami popełnianymi przez użytkowników.

\subsection{Interakcje społecznościowe: Komentarze i Oceny}
Moduł komentarzy został zaimplementowany w celu umożliwienia użytkownikom interakcji między sobą i wymiany informacji/opinii na temat danego 
zestawu fiszek. W początkowej fazie projektowania wymagań funkcjonalnych rozważano implementację modelu komenatrzy, pozwalającego na 
zagnieżdżanie komentarzy aż do 10 poziomów. Niestety ze względu na ograniczenia czasowe i większą priorytetyzację innych kluczowych 
funkcjonalności (np. wcześniej wspomniana strona publiczna), zdecydowano się na uproszczenie logiki biznesowej modułu komentarzy do 
jednego poziomu zagnieżdżania. Takie podejście dalej zapewni możliwość dyskusji na dane tematy, znacząco upraszczając implementację.

Pomimo zdecydowania się na uproszczony model modułu komentarzy, rozszerzenie funkcjonalności dalej pozostawało planem na przyszły 
rozwój aplikacji. Z tego powodu zaimplementowano hybrydowe podejście łączące mechanizm listy sąsiedztwa (adjacency list) z 
mechanizmem zmaterializowanej ścieżki (materialized path) opartym na rozszerzeniu PostgreSQL ltree. % \cite{13}
Zastosowanie tego rozwiązania przyniosło wiele korzyści:

\begin{itemize}
    \item \textbf{Odporność na zmianę wymagań} -- W przypadku powrotu do oryginalnych wymagań (zagnieżdżanie komentarzy do 10 poziomów),
    warstwa danych nie będzie wymagała żadnych modyfikacji ani migracji. Istniejące już zapytania do bazy danych wykorzystujące \texttt{path}
    będą działały tak samo wydajnie niezależnie od głębokości drzewa komentarzy. Takie podejście pozwala na uniknięcie długu technicznego 
    spowodowanego implementacją mniej wydajnych zapytań rekurencyjnych (Recursive CTE), które byłyby niezbędne przy zastosowaniu podejścia 
    samej listy sąsiedztwa.
    \item \textbf{Optymalizacja usuwania komentarzy} -- Niezależnie od ilości poziomów zagnieżdżenia usunięcie rodzica zawsze musi skutkować 
    usunięciem wszystkich dzieci. Ltree pozwala na optymalizację tej operacji, poprzez wykonanie jednego zapytania SQL przy użyciu 
    \texttt{descendant\_of}. Eliminuje to konieczność rekursywnego usuwania całej chierarchicznej struktury drzewa, znacznie optymalizując 
    wydajność serwera dla dużych ilości danych.
    \item \textbf{Pobieranie komentarzy} -- Proces pobierania komentarzy zakończony jest operacją \texttt{ORDER\_BY path}, co pozwala  na 
    oddelegowanie odpowiedzialności sortowania komentarzy do bazy danych. Mechanizm ten jest bardziej niezawodny niż sortowanie
    po dacie oraz zachowuje oryginalną chierarchię drzewa, co znacznie ułatwia stworzenie i wysłanie odpowiedzi do klienta.
\end{itemize}

Kluczowym wyzwaniem w hybrydowych modelach jest zachowanie synchronizacji między obiema strukturami przechowującymi dane 
(\texttt{parent\_comment\_id} i \texttt{path}). Mimo możliwości rozwiązania problemu w warstwie logiki biznesowej poprzez 
użycie transakcji SQL zdecydowano się oddelegować proces tworzenia i aktualizacji ścieżki bezpośrednio do warstwy danych.
Relacyjna baza danych posiada mechanizm wyzwalacza (trigger), który pozwala na łatwe utrzymanie integralności danych. 
Zastosowanie wyzwalacza niesie ze sobą dwie kluczowe korzyści:
\begin{itemize}
    \item \textbf{Minimalizacja zapytań do bazy danych (Round trip reduction)} -- Do wyliczenia ścieżki w systemach używających 
    mapowania ORM oraz kluczy autoinkrementowanych, potrzeba id nowego rekordu, który nadawany jest przez bazę danych. Realizacja 
    tego procesu po stronie serwera, wymaga dwóch zapytań do bazy danych. Najpierw wykonywany jest \texttt{INSERT} (w celu uzyskania ID), 
    a następnie \texttt{UPDATE} (w celu zapisania ścieżki). Dzięki zaimplementowaniu wyzwalacza nie trzeba wtórnie wykonywać aktualizacji 
    z poziomu aplikacji, enkapsulując całą logikę obliczania ścieżki w jednej operacji wstawienia danych.
    \item \textbf{Zapewnienie integralności danych} -- Wykorzystanie triggera pozwala na globalizacje procesu. Oznacza to, że niezależnie 
    od tego, czy dane wprowadzone zostały przez API serwera, migracje czy zapytania SQL, zmienna \texttt{path} zawsze będzie zaaktualizowana.
    Takie scentralizowanie znacząco poprawia czystość i przejrzystość kodu. 
\end{itemize} 

\begin{lstlisting}[language=SQL, 
caption={Wyzwalacz automatyzujący budowanie ścieżki}, 
label={lst:trigger_ltree}]
CREATE OR REPLACE FUNCTION set_comment_path() RETURNS TRIGGER AS
DECLARE
    parent_path ltree;
BEGIN
    IF NEW.parent_comment_id IS NULL THEN
        UPDATE comments SET path = NEW.id::text::ltree WHERE id = NEW.id;
    ELSE
        SELECT path INTO parent_path FROM comments WHERE id = NEW.parent_comment_id;
        UPDATE comments SET path = parent_path || NEW.id::text WHERE id = NEW.id;
    END IF;
    RETURN NEW;
END;

CREATE TRIGGER comment_path_trigger
AFTER INSERT ON comments
FOR EACH ROW EXECUTE PROCEDURE set_comment_path();
\end{lstlisting}
Przedstawiony powyżej algorytm (listing \ref{lst:trigger_ltree}) został zaimplementowany w języku PL/pgSQL.
Trigger został zdefiniowany jako \texttt{AFTER INSERT}, ponieważ budowa ścieżki wymaga znajomości klucza głównego 
danego rekordu. Działanie wyzwalacza przebiega następująco:
\begin{itemize}
    \item \textbf{Korzeń drzewa} -- Jeżeli pole \texttt{parent\_comment\_id} jest puste 
    (komentarz stanowi korzeń drzewa), funkcja tworzy nową ścieżkę rzutując id rekordu na typ \texttt{ltree}. 
    \item \textbf{Węzeł potomny} -- W przypadku węzła potomnego pobierana jest ścieżka rodzica do zmiennej \texttt{parent\_path}, 
    a następnie dołączane jest do niej id nowego komentarza. Takie podejście przyrostowo buduje hierarchiczną strukturę komentarzy, 
    zapewniając integralność danych.
\end{itemize}

Struktura danych dla systemu ocen została zdefiniowana wcześniej w Projekcie Systemu. Wyzwaniem implementacyjnym było stworzenie uniwersalnej logiki
obsługującej głosy dla wszystkich typów materiałów. Serwis \texttt{VoteService} realizuje to poprzez centralną metodę \texttt{process\_vote}, która 
zarządza oceną użytkownika niezależnie od materiału. Głównym mechanizmem implementacji jest proces przełączania głosu. Aby zapewnić dobry i intuicyjny 
interfejs użytkownika, logika biznesowa implementuje trzy scenariusze:
\begin{itemize}
    \item \textbf{Dodanie głosu} -- Jeżeli użytkownik nie zagłosował jeszcze, tworzony jest nowy rekord w tabeli \texttt{Votes}.
    \item \textbf{Zmiana głosu} -- W przypadku zmiany głosu, system aktualizuje głos, zmieniając jedynie \texttt{vote\_type}.
    \item \textbf{Usunięcie głosu} -- Ponowne wybranie tej samej oceny skutkuje usunięciem rekordu z bazy danych (odznaczenie głosu).
\end{itemize}
