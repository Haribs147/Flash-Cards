\chapter{Implementacja Systemu}
\label{ch:implementacja_systemu}

\section{Warstwa Prezentacji}

\section{Warstwa Logiki}
Backend zgodnie z projektem systemu, został zaimplementowany w języku Python, przy wykorzystaniu 
frameworku FastAPI. W przeciwieństwie do projektu systemu, gdzie opisywano podział logiczny, ten rozdział 
będzie opisywał organizację kodu, konfigurację serwera i mechanizmy scalające poszczególne komponenty systemu.

Kod źródłowy serwera jest zorganizowany w pakiety, odzwierciedlające podział na warstwy przyjęty podczas projektowania:
\begin{itemize}
    \item {\texttt{api/routes}} -- Zawiera definicję punktów końcowych, z których korzysta aplikacja kliencka.
    \item {\texttt{services}} -- Implementuje logikę biznesową aplikacji. Serwisy przetwarzają dane uzyskane od repozytoriów 
    i przekazują je do tras.
    \item {\texttt{repositories}} -- Warstwa dostępu do danych. Cały kod znajdujący się w tym pakiecie wykonuje bezpośrednie 
    zawołania do bazy danych, Elasticsearch lub MinIO w celu pobrania danych.
    \item {\texttt{api/schemas}} -- Przechowuje modele Pydantic (DTO) dla poszczególnych modułów.
    \item {\texttt{core}} -- Zawiera podstawowe konfiguracje systemu i często wykorzystywane funkcje pomocnicze.
    \item {\texttt{db}} -- Odpowiada za definicję modeli ORM oraz konfigurację połączenia z relacyjną bazą danych.
    \item {\texttt{external}} -- Zawiera pliki odpowiedzialne za inicjalizację i obsługę zewnętrznych systemów 
    (MinIO, ElasticSearch, Gemini).
\end{itemize}
Taka separacja pozwala na łatwe testowanie i utrzymanie kodu, ponieważ zmiany 
w logice biznesowej aplikacji, nie wymagają zmian w pakietach routes i repositories.
Każdy moduł systemu, zobrazowany na diagramie modułów funkcjonalności systemu 
(Rys \ref{rys:use_case_diagram}), posiada oddzielny router, serwis i repozytorium, 
co znacznie ułatwia poruszanie się po bazie kodu. 

Aplikacja do przechowywania wrażliwych danych konfiguracyjnych wykorzystuje bibliotekę pydantic-settings. 
Pozwala ona na walidowanie i wczytywanie wrażliwych danych (klucze API, sól, itp. ) z pliku .env do
klasy Settings. Dzięki temu aplikacja nie uruchomi się, jeżeli zabraknie któregoś z parametrów konfiguracyjnych 
w pliku .env.

Punktem wejściowym całego serwera jest plik main.py, w którym tworzony jest obiekt FastAPI. Podczas tworzenia instancji 
FastAPI, definiowany jest także cykl życia aplikacji. Pozwala on na zainicjalizowanie serwisów przed rozpoczęciem 
przyjmowania żądań od klienta i uruchomienie kodu czyszczącego po zakończeniu działania serwera. Szczególną rolę w tym procesie 
odgrywa zarządzanie połączeniami do poszczególnych źródeł danych. Tak jak wspomniano w rozdziale Projekt Systemu, zainicjalizowane 
zasoby są udostępniane komponentom systemu za pomocą mechanizmu wstrzykiwania zależności (Dependency Injection). W zależności od 
zasobu, przyjęto odmienne strategie zarządzania jego cyklem życia:
\begin{itemize}
    \item {\textbf{Relacyjna baza danych}} -- Do zarządzania połączeniem do relacyjnej bazy danych użyto mechanizmu sesji na żądanie 
    (session per request). Oznacza to, że każde zapytanie do serwera otrzymuje swoje własne połączenie do bazy danych, które wygasa po zwróceniu 
    wyniku do klienta.
    \item {\textbf{Wyszukiwarka pełnotekstowa}} -- Wyszukiwarki pełnotekstowe takie jak Elasticsearch posiadają wewnętrznego klienta 
    , który zarządza jego pulą połączeń HTTP. Do zarządzania jego cyklem życia stosuje się wzorzec Singleton. Oznacza to, że podczas inicjalizacji 
    aplikacji tworzona jest jedna wspólna instancja klienta ElasticSearch, która jest współdzielona przez wszystkie wątki i żądania. Dzięki temu aplikacja unika 
    kosztownego narzutu tworzenia nowego klienta dla każdego żądania.
\end{itemize}
Poniższy listing pokazuje implementację obu wyżej omówionych strategi. Funkcja \texttt{get\_db} wykorzystuje block try...finally
do bezpiecznego zamknięcia połączenia niezależnie od wyniku operacji. Z kolej funkcja \texttt{get\_es\_client} zwraca referencję do 
wcześniej zainicjalizowanego globalnego obiektu.

\begin{lstlisting}[language=Python,
	caption={Startegie zarządzania cyklem życia obiektu},
	label={lst:cykl_zycia}]
    # Session per request
    def get_db():
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()
    
    # Singleton
    def get_es_client():
        if es_client is None:
            raise RuntimeError(
                "Elasticsearch client is not initialized"
            )
        return es_client
\end{lstlisting} 


\subsection{Moduł Uwierzytelniania i zarządzania kontem}
Bezpieczeństwo aplikacji jest podstawą każdego systemu. Wszystkie mechanizmy powiązane z uwierzytelnianiem i zarządzaniem kontem 
znajdują się w serwisie \texttt{AuthService} i pakiecie \texttt{core.security}. W przeciwieństwie do prostych rozwiązań opierających 
się na przesyłaniu tokenów JWT w nagłówkach HTTP, zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów,
zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów. Proces logowania i utrzymywania sesji 
opiera się na dwóch tokenach:
\begin{itemize}
    \item \textbf{Access token} -- Krótkoterminowy token dostępu (ważny przez 5 minut) pozwalający na autoryzację użytkownika.
    \item \textbf{Refresh token} -- Długoterminowy token odświeżania (ważny przez 30 minut) służący do odnawiania sesji użytkownika, bez 
    konieczności ponownego logowania.
\end{itemize}
Oba tokeny nie są zwracane w ciele odpowiedzi (co tworzy podatność na ataki XSS), lecz ustawiane są jako ciasteczka z flagą \texttt{HttpOnly}. 
Takie rozwiązanie ma swoje wady i zalety, ponieważ uniemożliwia ono kradzież tokenów przy pomocy ataku XSS, 
lecz tworzy nowe zagrożenia takie jak np. atak Man-in-the-Middle (MitM) czy Cross-Site Request Forgery (CSRF). W celu zapobiegania tym 
atakom ciasteczko tworzone jest z dwiema dodatkowymi flagami:
\begin{itemize}
    \item \textbf{Secure} -- Przeglądarka dołącza ciasteczko z tokenem tylko wtedy, gdy strona korzysta z protokołu HTTPS, dzięki czemu 
    ciasteczko zawsze będzie zaszyfrowane.
    \item \textbf{SameSite=lax} -- Ogranicza wysyłanie ciasteczka między stronami. W trybie lax przeglądarka blokuje przesyłanie ciasteczka 
    do żądań zainicjowanych przez zewnętrzne serwisy, ale zezwala na jego przesłanie podczas nawigacji najwyższego poziomu (np. kliknięcie w link nawigujący do
    mojej aplikacji).
\end{itemize}
Ustawienie SameSite na \texttt{lax} lub \texttt{strict} nie broni całkowicie przed atakami CSRF. 
W przypadku ustawienia SameSite na \texttt{lax} atakujący może wymusić wysłanie żądania z ciasteczkiem, 
inicjując nawigację najwyższego poziomu za pomocą prostego żądania GET. Ustawienie SameSite na \texttt{strict} 
komplikuje atak, ale nadal można go przeprowadzić poprzez przekierowania po stronie klienta lub podatności na subdomenach.
W celu większego zabezpieczenia przed tym atakiem zaimplementowano wzorzec Signed Double Submit Cookie. Mechanizm ten 
polega na podpisaniu tokenu zapisanego w ciasteczku CSRF przy użyciu sekretnego klucza serwera. Podczas weryfikacji żądania 
serwer najpierw sprawdza poprawność podpisu tokena w ciasteczku, a następnie porównuje jego zawartość z tokenem przesłanym w 
nagłówku HTTP.

W serwerze zostały zaimplementowane dwa sposoby uwierzytelniania użytkownika oparte o mechanizm wstrzykiwania zależności:
\begin{itemize}
    \item \textbf{get\_current\_user} -- Stosowane do uwierzytelnienia użytkownika i uzyskania jego obiektu z bazy danych. 
    Używane w większości tras wymagających autoryzacji (np. tworzenie folderu, edycja materiałów). Weryfikuje on obecność 
    i poprawność access tokenu w ciasteczku przesłanym w żądaniu. W przypadku jego braku lub niezgodności, żądanie jest 
    przerywane błędem 401.
    \item \textbf{get\_optional\_current\_user} -- Stosowane w endpoincie do pobrania zestawu fiszek (\texttt{GET /sets/{id}}) 
    w celu sprawdzenia czy użytkownik jest zalogowany. W przypadku zalogowanego użytkownika system zwróci dodatkowe informacje, 
    takie jak np. głos użytkownika (upvote/downvote) i zapisze zestaw fiszek w ostatnio odwiedzanych zestawach. Niezalogowany użytkownik 
    otrzyma dostęp do zestawu fiszek, bez potrzeby logowania.
\end{itemize}

Największym wyzwaniem w implementacji tego rozwiązania było połączenie asynchronicznej biblioteki walidującej CSRF (fastapi\_csrf\_protect) 
z synchronicznymi endpointami. Zdefiniowanie punktów końcowych jako asynchroniczne znacznie spowolniłoby działanie aplikacji, ponieważ serwer 
używa synchronicznego sterownika bazy danych i ElasticSearch'a, co doprowadziłoby do zablokowania  głównej pętli zdarzeń (Event Loop). Problem 
ten rozwiązano wykorzystując wzorzec wstrzykiwania zależności. Walidację tokenu CSRF wydzielono do asynchronicznej funkcji, która uruchamiana 
jest asynchroniczne przed właściwą logiką endpointu. FastAPI jest w stanie optymalnie zarządzać kontekstem wykonania: walidacja tokena uruchamia 
się na pętli zdarzeń, a logika endpointu jest delegowana do osobnej puli wątków.

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    # Funkcja pomocnicza
    async def validate_csrf(
        request: Request, 
        csrf_protect: CsrfProtect = Depends()
    ):
        await csrf_protect.validate_csrf(request)

    # Endpoint w ktorym walidowany jest CSRF
    @router.post(
        "/materials/{material_id}/comments", 
        status_code=status.HTTP_201_CREATED, 
        response_model=CommentOut
    )
    def new_comment(
        material_id: int, 
        comment_data: CommentCreate, 
        db: Session = Depends(get_db), 
        current_user: User = Depends(get_current_user),
        comment_service: CommentService = Depends(CommentService),
        _ = Depends(validate_csrf)
    ):
        ...
\end{lstlisting} 
 
\subsection{Zarządzanie materiałami i zestawami fiszek}
Centralnym elementem aplikacji jest zarządzanie zasobami użytkownika. Na zasoby użytkownika składają się foldery i zestawy fiszek. Ze względu 
na chierachiczną strukturę danych i różne relacje między zasobami logika została podzielona na dwa współpracujące ze sobą serwisy: 
\texttt{MaterialService} i \texttt{FlashcardSetService}.

Zgodnie z przyjętym modelem bazy danych każdy materiał (folder/zestaw fiszek) jest reprezentowany przez encję \texttt{Materials}. Serwis 
\texttt{MaterialService} powstał w celu uniknięcia duplikacji kodu i odpowiada za podstawowe operacje wykonywane na materiałach 
(przenoszenie między folderami, zmiana nazwy itp.). Jest on warstwą abstrakcyjną nad operacjami wspólnymi dla wszystkich typów materiałów. 
Kluczowym elementem tego serwisu jest metoda 
\texttt{check\_permission}, która realizuje autoryzację do poszczególnych materiałow. Przed wykonaniem jakiejkolwiek operacji na zasobie, 
system za pomocą tej metody weryfikuje uprawnienia użytkownika w oparciu o:
\begin{enumerate}
    \item Własność zasobu (czy owner\_id jest taki sam jak id użytkownika)
    \item Status publiczny zasobu
    \item Udostępnienia zasobu (encja material\_shares)
\end{enumerate} 
Proces tworzenia folderów jest realizowany bezpośrednio przez \texttt{MaterialService}. Metoda \texttt{create\_folder} przyjmuje obiekt DTO, 
waliduje istnienie rodzica (jeżeli został podany) i tworzy nowy wiersz w tabeli materials z \texttt{item\_type="folder"}.  

Tworzenie zestawu fiszek jest bardziej skomplikowane, ponieważ wymaga zapisu do wielu tabel jednocześnie (\texttt{materials}, 
\texttt{flashcard\_sets} i \texttt{flashcards}). Proces ten składa się z dwóch etapów:
\begin{enumerate}
    \item Repozytorium materiałów jest wywoływane w celu stworzenia nowego materiału o typie \texttt{item\_type="set"}. Dzięki temu 
    nowy zestaw fiszek otrzymuje unikalne id i zostaje osadzony w hierarchicznej strukturze folderów.
    \item Następnie serwis wykorzystuje id nowo stworzonego materiału do zapisania szczegołów materiału (opis, widoczność) i listy fiszek
    w odpowiednich tabelach.
\end{enumerate} 

Proces tworzenia zestawu fiszek nie jest jednak najbardziej skomplikowaną operacją w obu tych serwisach. Aktualizacja zestawu fiszek, która 
jest relacją jeden do wielu (zestaw -- fiszki) często implementowana jest poprzez usunięcie wszystkich starych elementów w bazie danych i 
wstawieniu nowych, przychodzących z żądania. Nie jest to jednak idealne podejście, gdyż w przypadku małej zmiany w dużym zestawie fiszek (np. zmiana jednej fiszki), 
musi zostać wykonane N operacji usunięcia i N operacji wstawienia do bazy danych gdzie N to liczba fiszek w zestawie. Z tego powodu zastosowano 
prosty algorytm polegający na pobraniu wszystkich fiszek z bazy danych i porównaniu ich z danymi przychodzącymi z żądania. Fiszki posiadające ID w 
bazie danych są aktualizowane, nieposiadające ID dodawane, a nieistniejące w bazie danych usuwane. Taki mechanizm minimalizuje liczbę operacji 
wykonywanych na bazie danych i zachowuje spójność kluczy głównych fiszek.

Istotnym aspektem opearcji zapisu do bazy danych jest zapewnienie bezpieczeństwa użytkowników, później wyświetlających zapisane dane. 
Jako że aplikacja pozwala na formatowanie tekstu, treść fiszek jest zapisywana i wyświetlana jako HTML, co rodzi ryzyko ataków XSS. 
Aby temu zapobiec, zaimplementowano mechanizm sanityzacji danych wejściowych oraz wyjściowych przekazywanych użytkownikowi. Proces 
sanityzacji danych tekstowych został zaimplementowany przy pomocy biblioteki nh3, która pozwala na zdefiniowanie tagów i atrybutów, 
które nie zostaną zakodowane. Aby ułatwić zarządzanie sanityzacją danych, cały proces oczyszczania został 
zintegrowany w niestandardową definicję typu danych \texttt{SanitizedStr}, stworzoną za pomocą biblioteki Pydantic. SanitizedStr 
wykorzystuje mechanizm \texttt{AfterValidator} do wywołania procesu sanityzacji danych dla każdego pola modelu Pydantic oznaczonego 
tym typem. Takie podejście zapewnia czystość kodu, poprzez automatyzację i centralizację logiki sanityzacji.

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    
    SanitizedStr = Annotated[str, AfterValidator(sanitize_html)]

    class FlashcardData(BaseModel):
        model_config = ConfigDict(from_attributes=True)

        id: Optional[int] = None
        front_content: SanitizedStr
        back_content: SanitizedStr
\end{lstlisting} 

Istotnym wyzwaniem implementacyjnym była obsługa pobierania szczegółów zestawu fiszek (metoda \texttt{get\_full\_set\_details}).
Ze względu na fakt, że wyświetlanie zestawu fiszek jest operacją najczęściej wykonywaną przez użytkowników, proces ten musiał zostać odpowiednio zoptymalizowany. 
Metoda ta pełni rolę agregatora danych, ponieważ pobiera listę fiszek, komentarze, udostępnienia i agreguje głosy. W pierwszej kolejności serwer 
weryfikuje typ materiału. W przypadku napotkania skrótu (\texttt{item\_type="link"}) system pobiera wyżej wspomniane dane z materiału źródłowego, przy 
jednoczesnym zachowaniu uprawnień użytkownika. Cały proces kończy się logowaniem wyświetlenia zestawu fiszek do indeksu 
\texttt{view\_events} w ElasticSearch, co pozwala na późniejsze generowanie rankingu fiszek na stronie publicznej bez obciążania relacyjnej bazy danych.

System umożliwia także funkcjonalność kopiowania zestawów fiszek. Operacja ta pozwala użytkownikowi stworzyć głęboką kopię dowolnego zestawu fiszek, do którego 
posiada dostęp. Logika biznesowa tego procesu polega na utworzeniu nowego materiału o typie \texttt{item\_type="set"}, a następnie zduplikowaniu wszystkich 
powiązanych fiszek z oryginalnego materiału. Dzięki temu użytkownik jest właścicielem zkopiowanego zestawu, co pozwala użytkownikowi na swobodną edycję i nadawanie 
uprawnień bez modyfikacji oryginalnego materiału.

\subsection{Przeglądanie i wyszukiwanie publicznych materiałów}
Implementacja publicznych funkcjonalności wymagała zintegrowania zewnętrznych systemów i wykroczenia poza ramy standardowej relacyjnej bazy danych. 
W przeciwieństwie do innych modułów (obsługujących prywatne materiały), gdzie ważna była spójność transakcji i zasady ACID, w tym przypadku postawiono 
na szybkość obsługi zapytań i asynchroniczne przetwarzanie tekstu.

Zaimplementowanie wyszukiwarki pełnotekstowej wymagało zbudowania odwróconego indeksu, aby jak najbardziej zoptymalizować wyszukiwanie. Jednym z kluczowych 
wyzwań implementacyjnych, był wybór danych, po których działałaby wyszukiwarka. Opieranie mechanizmu wyszukiwania wyłącznie na nazwie i opisie fiszki, mogłoby 
prowadzić do katastrofalnych skutków, gdyż użytkownicy mogliby pozostawić te pola puste lub stosować nazwy nieoddające merytoryki zestawu (np. "Sprawdzian angielski").
Z drugiej strony, podejście polegające na wyszukiwaniu na podstawie treści wszystkich fiszek znajdujących się w zestawie mogłoby prowadzić do nadmiaru danych. Nadmiar 
danych prowadziłby do szumu informacyjnego, więc serwer zwracałby zestawy fiszek zawierające słowo klucz, ale nietrafione kontekstowo.

W celu zapewnienia kompromisu 
między wydajnością a trafnością wyników zaimplementowano mechanizm automatycznego generowania tagów, opisujących zestaw fiszek. Słowa kluczowe generowane są przy 
pomocy modelu językowego Google Gemini 2.5 Flash, który analizuje całą treść tekstową wszystkich fiszek danego zestawu. Do modelu przekazywana jest jedynie treść 
fiszek bez zachowania tagów HTML i plików graficznych. Wstępne przetworzenie tekstu pozwoliło na zminimalizowanie wykorzystywanej liczby tokenów wejściowych, 
zmniejszenie czasu przetwarzania zapytania przez model i ograniczenia informacji przekazywanych do modelu, które mogłyby rozproszyć model, powodując halucynacje.

Kluczowym elementem było stworzenie jasnego zapytania dla modelu, tak aby ten zwrócił jak najbardziej deterministyczną i najtrafniejszą odpowiedź (prompt engeenering). 
Prompt składa się z trzech sekcji:
\begin{itemize}
    \item \textbf{Definicja roli i zadania} -- Nadaje modelowi odpowiedni kontekst, pozwalający na lepsze dopasowanie odpowiedzi.
    \item \textbf{Ustawienie reguł} -- Ograniczenia nałożone na model odgrywają kluczową rolę w formacie jego odpowiedzi.
    \item \textbf{Przekazanie danych} -- Przekazanie nazwy, opisu i zawartości zestawu fiszek.
\end{itemize}

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    prompt = f"""
    You are an expert educational content analyzer and tagging assistant. 
    Your goal is to generate metadata for flashcards to improve searchability.

    Analyze the provided flashcard set and generate a list of relevant semantic tags.

    Rules:
    - Return the tags as a JSON object with a single key named: "tags" which would contain a list of tags (strings).
    - The "tags" list must contain between 5 and 15 strings.
    - Tags should be 1-2 words maximum.
    - Tags HAVE to be in lowercase.
    
    Input Data:
    <flashcard_set>
        <name>{name}</name>
        <description>{description}</description>
        <content>
        {flashcards_content}
        </content>
    </flashcard_set>
    """
\end{lstlisting} 

Google Gemini API pozwala także na konfigurację żądania i zachowania modelu. Zamiast polegać wyłącznie na tekstowych zasadach 
przekazanych w prompcie, zdefiniowano schemat danych wyjściowych przy pomocy modelu biblioteki Pydantic. 
Przekazanie tego schematu do konfiguracji modelu wymusza na nim zwrócenie odpowiedzi w odpowiednim, poprawnym formacie JSON. Skonfigurowano 
także filtry bezpieczeństwa o wysokim progu blokowania (\texttt{BLOCK\_ONLY\_HIGH}), aby zapobiec błędnej klasyfikacji zestawów 
fiszek o tematyce edukacyjnej podobnej do filtrów (np. z zakresu historii wojen czy anatomii człowieka). Obniżono 
temperaturę modelu do 0.2 co ogranicza losowość i czyni jego odpowiedzi bardziej konkretnymi oraz deterministycznymi. Jako dodatkowe 
zabezpieczenie, ograniczono zużycie modelu do 500 tokenów, aby nie zużył on dużej ilości tokenów w przypadku błędnego zinterpretowania 
promptu.

Integracja z zewnętrznymi modelami LLM wiąże się z nieprzewidywalnym czasem odpowiedzi, zależnym od 
rodzaju modelu, informacji mu przekazywanych i długości jego odpowiedzi. Synchroniczne generowanie tagów drastycznie 
zmniejszałoby responsywność aplikacji, blokując główny wątek przetwarzający żądanie HTTP. Aby temu zapobiec, proces 
generowania tagów jest wykonywany przy pomocy zadań w tle (background task). BackgroundTasks jest wbudowanym mechanizmem 
FastAPI pozwalającym na wykonanie metody po zwróceniu odpowiedzi HTTP do użytkownika. Proces generowania tagów jest inicjowany 
przy każdym utworzeniu lub edycji zestawu fiszek. Serwer po otrzymaniu żądania zapisuje zmiany w relacyjnej bazie danych, a następnie 
tuż przed zwróceniem odpowiedzi dodaje zadanie do kolejki w celu wygenerowania i zaindeksowania nowych tagów.

Do implementacji wyszukiwania wykorzystano zapytanie ElasticSearch typu \texttt{multi\_match}, który pozwala na 
przeszukiwanie wielu pól jednocześnie. W podstawowej konfiguracji multi\_match zwraca zestaw o polu posiadającym największy wynik, 
ignorując pozostałe. Aby w pełni wykorzystać zgromadzone dane, rozszerzono konfigurację multi\_match o dwa dodatkowe mechanizmy 
rankingowania:
\begin{itemize}
    \item \textbf{System wag} -- Zastosowany został system wag dla wszystkich pól wyszukiwania. Nazwa zestawu posiada najwyższą wagę (x3),
    wygenerowane tagi średnią (x2), a opis zestawu fiszek najmniejszą (x1).
    \item \textbf{Tie\_breaker} -- Tie breaker pozwala na zsumowanie wyników wyszukiwania ze wszystkich pól, co oznacza, że zestaw fiszek pasujący 
    w nazwie i opisie, nie będzie miał tyle samo punktów co zestaw pasujący tylko w nazwie. Został on ustawiony na wartość 0.3 co powoduje, że do 
    wyniku z najbardziej dopasowanego pola dodawane są wyniki z innych pól pomnożone o wartość tie\_breaker'a.
\end{itemize}
Dodatkowo ustawiony parametr \texttt{fuzziness="AUTO"}, chroni wyszukiwarkę przed literówkami popełnianymi przez użytkowników.
