\chapter{Implementacja Systemu}
\label{ch:implementacja_systemu}

\section{Warstwa Prezentacji}

\section{Warstwa Logiki}
Backend zgodnie z projektem systemu, został zaimplementowany w języku Python, przy wykorzystaniu 
frameworku FastAPI. W przeciwieństwie do projektu systemu, gdzie opisywano podział logiczny, ten rozdział 
będzie opisywał organizację kodu, konfigurację serwera i mechanizmy scalające poszczególne komponenty systemu.

Kod źródłowy serwera jest zorganizowany w pakiety, odzwierciedlające podział na warstwy przyjęty podczas projektowania:
\begin{itemize}
    \item {\texttt{api/routes}} -- Zawiera definicję punktów końcowych, z których korzysta aplikacja kliencka.
    \item {\texttt{services}} -- Implementuje logikę biznesową aplikacji. Serwisy przetwarzają dane uzyskane od repozytoriów 
    i przekazują je do tras.
    \item {\texttt{repositories}} -- Warstwa dostępu do danych. Cały kod znajdujący się w tym pakiecie wykonuje bezpośrednie 
    zawołania do bazy danych, Elasticsearch lub MinIO w celu pobrania danych.
    \item {\texttt{api/schemas}} -- Przechowuje modele Pydantic (DTO) dla poszczególnych modułów.
    \item {\texttt{core}} -- Zawiera podstawowe konfiguracje systemu i często wykorzystywane funkcje pomocnicze.
    \item {\texttt{db}} -- Odpowiada za definicję modeli ORM oraz konfigurację połączenia z relacyjną bazą danych.
    \item {\texttt{external}} -- Zawiera pliki odpowiedzialne za inicjalizację i obsługę zewnętrznych systemów 
    (MinIO, ElasticSearch, Gemini).
\end{itemize}
Taka separacja pozwala na łatwe testowanie i utrzymanie kodu, ponieważ zmiany 
w logice biznesowej aplikacji, nie wymagają zmian w pakietach routes i repositories.
Każdy moduł systemu, zobrazowany na diagramie modułów funkcjonalności systemu 
(Rys \ref{rys:use_case_diagram}), posiada oddzielny router, serwis i repozytorium, 
co znacznie ułatwia poruszanie się po bazie kodu. 

Aplikacja do przechowywania wrażliwych danych konfiguracyjnych wykorzystuje bibliotekę pydantic-settings. 
Pozwala ona na walidowanie i wczytywanie wrażliwych danych (klucze API, sól, itp. ) z pliku .env do
klasy Settings. Dzięki temu aplikacja nie uruchomi się, jeżeli zabraknie któregoś z parametrów konfiguracyjnych 
w pliku .env.

Punktem wejściowym całego serwera jest plik main.py, w którym tworzony jest obiekt FastAPI. Podczas tworzenia instancji 
FastAPI, definiowany jest także cykl życia aplikacji. Pozwala on na zainicjalizowanie serwisów przed rozpoczęciem 
przyjmowania żądań od klienta i uruchomienie kodu czyszczącego po zakończeniu działania serwera. Szczególną rolę w tym procesie 
odgrywa zarządzanie połączeniami do poszczególnych źródeł danych. Tak jak wspomniano w rozdziale Projekt Systemu, zainicjalizowane 
zasoby są udostępniane komponentom systemu za pomocą mechanizmu wstrzykiwania zależności (Dependency Injection). W zależności od 
zasobu, przyjęto odmienne strategie zarządzania jego cyklem życia:
\begin{itemize}
    \item {\textbf{Relacyjna baza danych}} -- Do zarządzania połączeniem do relacyjnej bazy danych użyto mechanizmu sesji na żądanie 
    (session per request). Oznacza to, że każde zapytanie do serwera otrzymuje swoje własne połączenie do bazy danych, które wygasa po zwróceniu 
    wyniku do klienta.
    \item {\textbf{Wyszukiwarka pełnotekstowa}} -- Wyszukiwarki pełnotekstowe takie jak Elasticsearch posiadają wewnętrznego klienta 
    , który zarządza jego pulą połączeń HTTP. Do zarządzania jego cyklem życia stosuje się wzorzec Singleton. Oznacza to, że podczas inicjalizacji 
    aplikacji tworzona jest jedna wspólna instancja klienta ElasticSearch, która jest współdzielona przez wszystkie wątki i żądania. Dzięki temu aplikacja unika 
    kosztownego narzutu tworzenia nowego klienta dla każdego żądania.
\end{itemize}
Poniższy listing pokazuje implementację obu wyżej omówionych strategi. Funkcja \texttt{get\_db} wykorzystuje block try...finally
do bezpiecznego zamknięcia połączenia niezależnie od wyniku operacji. Z kolej funkcja \texttt{get\_es\_client} zwraca referencję do 
wcześniej zainicjalizowanego globalnego obiektu.

\begin{lstlisting}[language=Python,
	caption={Startegie zarządzania cyklem życia obiektu},
	label={lst:cykl_zycia}]
    # Session per request
    def get_db():
        db = SessionLocal()
        try:
            yield db
        finally:
            db.close()
    
    # Singleton
    def get_es_client():
        if es_client is None:
            raise RuntimeError(
                "Elasticsearch client is not initialized"
            )
        return es_client
\end{lstlisting} 


\subsection{Moduł Uwierzytelniania i zarządzania kontem}
Bezpieczeństwo aplikacji jest podstawą każdego systemu. Wszystkie mechanizmy powiązane z uwierzytelnianiem i zarządzaniem kontem 
znajdują się w serwisie \texttt{AuthService} i pakiecie \texttt{core.security}. W przeciwieństwie do prostych rozwiązań opierających 
się na przesyłaniu tokenów JWT w nagłówkach HTTP, zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów,
zaimplementowane rozwiązanie wykorzystuje ciasteczka do przechowywania i przesyłania tokenów. Proces logowania i utrzymywania sesji 
opiera się na dwóch tokenach:
\begin{itemize}
    \item \textbf{Access token} -- Krótkoterminowy token dostępu (ważny przez 5 minut) pozwalający na autoryzację użytkownika.
    \item \textbf{Refresh token} -- Długoterminowy token odświeżania (ważny przez 30 minut) służący do odnawiania sesji użytkownika, bez 
    konieczności ponownego logowania.
\end{itemize}
Oba tokeny nie są zwracane w ciele odpowiedzi (co tworzy podatność na ataki XSS), lecz ustawiane są jako ciasteczka z flagą \texttt{HttpOnly}. 
Takie rozwiązanie ma swoje wady i zalety, ponieważ uniemożliwia ono kradzież tokenów przy pomocy ataku XSS, 
lecz tworzy nowe zagrożenia takie jak np. atak Man-in-the-Middle (MitM) czy Cross-Site Request Forgery (CSRF). W celu zapobiegania tym 
atakom ciasteczko tworzone jest z dwiema dodatkowymi flagami:
\begin{itemize}
    \item \textbf{Secure} -- Przeglądarka dołącza ciasteczko z tokenem tylko wtedy, gdy strona korzysta z protokołu HTTPS, dzięki czemu 
    ciasteczko zawsze będzie zaszyfrowane.
    \item \textbf{SameSite=lax} -- Ogranicza wysyłanie ciasteczka między stronami. W trybie lax przeglądarka blokuje przesyłanie ciasteczka 
    do żądań zainicjowanych przez zewnętrzne serwisy, ale zezwala na jego przesłanie podczas nawigacji najwyższego poziomu (np. kliknięcie w link nawigujący do
    mojej aplikacji).
\end{itemize}
Ustawienie SameSite na \texttt{lax} lub \texttt{strict} nie broni całkowicie przed atakami CSRF. 
W przypadku ustawienia SameSite na \texttt{lax} atakujący może wymusić wysłanie żądania z ciasteczkiem, 
inicjując nawigację najwyższego poziomu za pomocą prostego żądania GET. Ustawienie SameSite na \texttt{strict} 
komplikuje atak, ale nadal można go przeprowadzić poprzez przekierowania po stronie klienta lub podatności na subdomenach.
W celu większego zabezpieczenia przed tym atakiem zaimplementowano wzorzec Signed Double Submit Cookie. Mechanizm ten 
polega na podpisaniu tokenu zapisanego w ciasteczku CSRF przy użyciu sekretnego klucza serwera. Podczas weryfikacji żądania 
serwer najpierw sprawdza poprawność podpisu tokena w ciasteczku, a następnie porównuje jego zawartość z tokenem przesłanym w 
nagłówku HTTP.

W serwerze zostały zaimplementowane dwa sposoby uwierzytelniania użytkownika oparte o mechanizm wstrzykiwania zależności:
\begin{itemize}
    \item \textbf{get\_current\_user} -- Stosowane do uwierzytelnienia użytkownika i uzyskania jego obiektu z bazy danych. 
    Używane w większości tras wymagających autoryzacji (np. tworzenie folderu, edycja materiałów). Weryfikuje on obecność 
    i poprawność access tokenu w ciasteczku przesłanym w żądaniu. W przypadku jego braku lub niezgodności, żądanie jest 
    przerywane błędem 401.
    \item \textbf{get\_optional\_current\_user} -- Stosowane w endpoincie do pobrania zestawu fiszek (\texttt{GET /sets/{id}}) 
    w celu sprawdzenia czy użytkownik jest zalogowany. W przypadku zalogowanego użytkownika system zwróci dodatkowe informacje, 
    takie jak np. głos użytkownika (upvote/downvote) i zapisze zestaw fiszek w ostatnio odwiedzanych zestawach. Niezalogowany użytkownik 
    otrzyma dostęp do zestawu fiszek, bez potrzeby logowania.
\end{itemize}

Największym wyzwaniem w implementacji tego rozwiązania było połączenie asynchronicznej biblioteki walidującej CSRF (fastapi\_csrf\_protect) 
z synchronicznymi endpointami. Zdefiniowanie punktów końcowych jako asynchroniczne znacznie spowolniłoby działanie aplikacji, ponieważ serwer 
używa synchronicznego sterownika bazy danych i ElasticSearch'a, co doprowadziłoby do zablokowania  głównej pętli zdarzeń (Event Loop). Problem 
ten rozwiązano wykorzystując wzorzec wstrzykiwania zależności. Walidację tokenu CSRF wydzielono do asynchronicznej funkcji, która uruchamiana 
jest asynchroniczne przed właściwą logiką endpointu. FastAPI jest w stanie optymalnie zarządzać kontekstem wykonania: walidacja tokena uruchamia 
się na pętli zdarzeń, a logika endpointu jest delegowana do osobnej puli wątków.

\begin{lstlisting}[language=Python,
	caption={Asynchroniczna zależność w synchronicznym endpoincie},
	label={lst:cykl_zycia}]
    # Funkcja pomocnicza
    async def validate_csrf(
        request: Request, 
        csrf_protect: CsrfProtect = Depends()
    ):
        await csrf_protect.validate_csrf(request)

    # Endpoint w ktorym walidowany jest CSRF
    @router.post(
        "/materials/{material_id}/comments", 
        status_code=status.HTTP_201_CREATED, 
        response_model=CommentOut
    )
    def new_comment(
        material_id: int, 
        comment_data: CommentCreate, 
        db: Session = Depends(get_db), 
        current_user: User = Depends(get_current_user),
        comment_service: CommentService = Depends(CommentService),
        _ = Depends(validate_csrf)
    ):
        ...
\end{lstlisting} 
 
\subsection{Zarządzanie materiałami i zestawami fiszek}
Centralnym elementem aplikacji jest zarządzanie zasobami użytkownika. Na zasoby użytkownika składają się foldery i zestawy fiszek. Ze względu 
na chierachiczną strukturę danych i różne relacje między zasobami logika została podzielona na dwa współpracujące ze sobą serwisy: 
\texttt{MaterialService} i \texttt{FlashcardSetService}.

Zgodnie z przyjętym modelem bazy danych każdy materiał (folder/zestaw fiszek) jest reprezentowany przez encję \texttt{Materials}. Serwis 
\texttt{MaterialService} powstał w celu uniknięcia duplikacji kodu i odpowiada za podstawowe operacje wykonywane na materiałach 
(przenoszenie między folderami, zmiana nazwy itp.). Jest on warstwą abstrakcyjną nad operacjami wspólnymi dla wszystkich typów materiałów. 
Kluczowym elementem tego serwisu jest metoda 
\texttt{check\_permission}, która realizuje autoryzację do poszczególnych materiałow. Przed wykonaniem jakiejkolwiek operacji na zasobie, 
system za pomocą tej metody weryfikuje uprawnienia użytkownika w oparciu o:
\begin{enumerate}
    \item Własność zasobu (czy owner\_id jest taki sam jak id użytkownika)
    \item Status publiczny zasobu
    \item Udostępnienia zasobu (encja material\_shares)
\end{enumerate} 
Proces tworzenia folderów jest realizowany bezpośrednio przez \texttt{MaterialService}. Metoda \texttt{create\_folder} przyjmuje obiekt DTO, 
waliduje istnienie rodzica (jeżeli został podany) i tworzy nowy wiersz w tabeli materials z \texttt{item\_type="folder"}.  

Tworzenie zestawu fiszek jest bardziej skomplikowane, ponieważ wymaga zapisu do wielu tabel jednocześnie (\texttt{materials}, 
\texttt{flashcard\_sets} i \texttt{flashcards}). Proces ten składa się z dwóch etapów:
\begin{enumerate}
    \item Repozytorium materiałów jest wywoływane w celu stworzenia nowego materiału o typie \texttt{item\_type="set"}. Dzięki temu 
    nowy zestaw fiszek otrzymuje unikalne id i zostaje osadzony w hierarchicznej strukturze folderów.
    \item Następnie serwis wykorzystuje id nowo stworzonego materiału do zapisania szczegołów materiału (opis, widoczność) i listy fiszek
    w odpowiednich tabelach.
\end{enumerate} 

Proces tworzenia zestawu fiszek nie jest jednak najbardziej skomplikowaną operacją w obu tych serwisach. Aktualizacja zestawu fiszek, która 
jest relacją jeden do wielu (zestaw -- fiszki) często implementowana jest poprzez usunięcie wszystkich starych elementów w bazie danych i 
wstawieniu nowych, przychodzących z żądania. Nie jest to jednak idealne podejście, gdyż w przypadku małej zmiany w dużym zestawie fiszek (np. zmiana jednej fiszki), 
musi zostać wykonane N operacji usunięcia i N operacji wstawienia do bazy danych gdzie N to liczba fiszek w zestawie. Z tego powodu zastosowano 
prosty algorytm polegający na pobraniu wszystkich fiszek z bazy danych i porównaniu ich z danymi przychodzącymi z żądania. Fiszki posiadające ID w 
bazie danych są aktualizowane, nieposiadające ID dodawane, a nieistniejące w bazie danych usuwane. Taki mechanizm minimalizuje liczbę operacji 
wykonywanych na bazie danych i zachowuje spójność kluczy głównych fiszek.

Istotnym wyzwaniem implementacyjnym była obsługa pobierania szczegółów zestawu fiszek (metoda \texttt{get\_full\_set\_details}).
Ze względu na fakt, że wyświetlanie zestawu fiszek jest operacją najczęściej wykonywaną przez użytkowników, proces ten musiał zostać odpowiednio zoptymalizowany. 
Metoda ta pełni rolę agregatora danych, ponieważ pobiera listę fiszek, komentarze, udostępnienia i agreguje głosy. W pierwszej kolejności serwer 
weryfikuje typ materiału. W przypadku napotkania skrótu (\texttt{item\_type="link"}) system pobiera wyżej wspomniane dane z materiału źródłowego, przy 
jednoczesnym zachowaniu uprawnień użytkownika. Cały proces kończy się logowaniem wyświetlenia zestawu fiszek do indeksu 
\texttt{view\_events} w ElasticSearch, co pozwala na późniejsze generowanie rankingu fiszek na stronie publicznej bez obciążania relacyjnej bazy danych.

System umożliwia także funkcjonalność kopiowania zestawów fiszek. Operacja ta pozwala użytkownikowi stworzyć głęboką kopię dowolnego zestawu fiszek, do którego 
posiada dostęp. Logika biznesowa tego procesu polega na utworzeniu nowego materiału o typie \texttt{item\_type="set"}, a następnie zduplikowaniu wszystkich 
powiązanych fiszek z oryginalnego materiału. Dzięki temu użytkownik jest właścicielem zkopiowanego zestawu, co pozwala użytkownikowi na swobodną edycję i nadawanie 
uprawnień bez modyfikacji oryginalnego materiału.

\subsection{Przeglądanie i wyszukiwanie publicznych materiałów}
Implementacja publicznych funkcjonalności wymagała zintegrowania zewnętrznych systemów i wykroczenia poza ramy standardowej relacyjnej bazy danych. 
W przeciwieństwie do innych modółów obsługujących prywatne materiały, gdzie ważna była spójność transakcji i zasady ACID, w tym przypadku postawiono 
na szybkość obsługi zapytań i asynchroniczne przetwarzanie tekstu.
\section{Opis wybranych modułów}  